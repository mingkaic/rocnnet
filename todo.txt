tenncor:
- implement convolution operator; backprop
- shape and preparation functors should ideally use C++17 variant
	(replace with resulting shape and temporary cache)
- remove move and clone functions for classes that don't need it
- define alloc shape as mutable and allowed shape as immutable (enforce this rule)
	placeholder of (4, 0) should accept input of size of any multiple of 4
- refine shape flexibility e.g: (4,) == (4,1)
	also any shape padded by 0 or 1 maybe “optimized” for lower dimensional shape
	(this should be an option, since some applications may not want to lose this information)
- possible dangling pointers by propagating destruction in the graph
- x~10 speed boost (tensorflow's CPU-only 32, 200, 200, 4 dqn 
	with tanh, tanh, identity activators) [target on mac: ~0.01s per training operation]
- define data format: associate dimensions to some label (i.e.: [default] dim 0 = col, dim 1 = row)

evaluate rocnnet principles:
- practicality
- efficiency
– logical correctness
- testability/program transparency

interesting ideas:
- variable batch size (increasing batch size over generations)

tests:
- improve tests (test base_immutable and immutable separately)

need testing:
- copying and moving observers on multiple unmanaged constants
- detaching unmanaged constants from observers
- copying immutable of uninitialized variables
- updates should be handled by graph_manager
- reactive updates by default should be restricted to unary connectors, n-ary connectors should update lazily