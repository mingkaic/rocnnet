{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, NL, HumanController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_settings = {\n",
    "    'objects': [\n",
    "        'friend',\n",
    "        'enemy',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'hero':   'yellow',\n",
    "        'friend': 'green',\n",
    "        'enemy':  'red',\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'friend': 0.1,\n",
    "        'enemy': -0.1,\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (700,500),\n",
    "    'hero_initial_position': [400, 300],\n",
    "    'hero_initial_speed':    [0,   0],\n",
    "    \"maximum_speed\":         [50, 50],\n",
    "    \"object_radius\": 10.0,\n",
    "    \"num_objects\": {\n",
    "        \"friend\" : 25,\n",
    "        \"enemy\" :  25,\n",
    "    },\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 120.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -0.0,\n",
    "    \"delta_v\": 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_control = False\n",
    "\n",
    "if human_control:\n",
    "    # WSAD CONTROL (requires extra setup - check out README)\n",
    "    current_controller = HumanController({b\"w\": 3, b\"d\": 0, b\"s\": 1,b\"a\": 2,}) \n",
    "else:\n",
    "    # The optimizer to use. Here we use RMSProp as recommended\n",
    "    # by the publication\n",
    "\n",
    "    # DiscreteDeepQ object\n",
    "    current_controller = DiscreteDeepQ(g.observation_size, \n",
    "                                       [200, 200, g.num_actions], \n",
    "                                       [NL.TANH, NL.TANH, NL.IDENTITY], \n",
    "                                       learning_rate=0.001, decay=0.9,\n",
    "                                       discount_rate=0.99, \n",
    "                                       exploration_period=5000, \n",
    "                                       max_experience=10000, \n",
    "                                       store_every_nth=4, \n",
    "                                       train_every_nth=4)\n",
    "    current_controller.initialize('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = True\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 50\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "    \n",
    "try:\n",
    "    simulate(simulation=g,\n",
    "             controller=current_controller,\n",
    "             fps=FPS,\n",
    "             visualize_every=VISUALIZE_EVERY,\n",
    "             action_every=ACTION_EVERY,\n",
    "             wait=WAIT,\n",
    "             disable_training=False,\n",
    "             simulation_resolution=0.001,\n",
    "             save_path=None)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Reward over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.plot_reward(smoothing=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing what the agent is seeing\n",
    "\n",
    "Starting with the ray pointing all the way right, we have one row per ray in clockwise order.\n",
    "The numbers for each ray are the following:\n",
    "- first three numbers are normalized distances to the closest visible (intersecting with the ray) object. If no object is visible then all of them are $1$. If there's many objects in sight, then only the closest one is visible. The numbers represent distance to friend, enemy and wall in order.\n",
    "- the last two numbers represent the speed of moving object (x and y components). Speed of wall is ... zero.\n",
    "\n",
    "Finally the last two numbers in the representation correspond to speed of the hero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.__class__ = KarpathyGame\n",
    "np.set_printoptions(formatter={'float': (lambda x: '%.2f' % (x,))})\n",
    "x = g.observe()\n",
    "new_shape = (x[:-4].shape[0]//g.eye_observation_size, g.eye_observation_size)\n",
    "print(x[:-4].reshape(new_shape))\n",
    "print(x[-4:])\n",
    "g.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
